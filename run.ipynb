{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "####\n",
    "#TODO\n",
    "\n",
    "# aussi il y a un biais au debut quil faudrait corriger en fonction de la loneur du path\n",
    "# peut etre qu il faudrait calculer le nb de possibile paths\n",
    "# reduire le sampling \n",
    "\n",
    "# faire symbolic\n",
    "# warnings\n",
    "# initialiser h0 pour rontrainer\n",
    "# check if sub and divide takes x0 and x1 in the good order\n",
    "# remove is_none I think it's useless \n",
    "\n",
    "import numpy as np\n",
    "from Loss import Loss\n",
    "from RON import RecurrentOccamNet\n",
    "from RONTrainer import RONTrainer\n",
    "from cocob import COCOBBackprop \n",
    "from bases import *\n",
    "\n",
    "X = [[np.array([np.cos(i), 1/100], dtype=np.float64)] for i in range(5)]\n",
    "\n",
    "Y = []\n",
    "W = []\n",
    "w = np.array([1., 1.])\n",
    "for x in X:\n",
    "    y = np.sin(np.dot(x[0],w))\n",
    "    w += x[0]*y\n",
    "    Y.append([y])\n",
    "    W.append(np.array(w.copy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_model = RecurrentOccamNet([2], 2, [1], \n",
    "                            [[on_sin(), on_cos(), on_sum(), on_dot(), on_mul()],\n",
    "                             [on_sin(), on_cos(), on_sum(), on_dot(), on_mul()],\n",
    "                             [on_sin(), on_cos(), on_sum(), on_dot(), on_mul()], \n",
    "                            [on_identity(), on_identity()]], \n",
    "                            [0.01, 0.01, 0.01, 0.01], \n",
    "                            skip_connections=True, is_none=False)\n",
    "criterion = Loss(0.01)\n",
    "optimizer = COCOBBackprop(r_model.parameters())\n",
    "trainer = RONTrainer(r_model, criterion, optimizer)\n",
    "\n",
    "trained_model = trainer.fit(X, Y, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(trained_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.samples_paths_and_probas(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "nb_sampled_paths = 1\n",
    "\n",
    "#X = [x.append(np.array([None])) for x in X]\n",
    "X = [[copy.deepcopy(x) for _ in range(nb_sampled_paths)] for x in X]\n",
    "# Reshape Y so that shape == (nb elements, output dim).\n",
    "Y = torch.tensor(Y, requires_grad = False)\n",
    "\n",
    "the_paths, the_keys_probas, the_keys_path2 = trained_model.samples_paths_and_probas(nb_sampled_paths)\n",
    "\n",
    "for x, y in zip(X, Y):\n",
    "    # This imply to compute the pred of the model for each sampled path\n",
    "    pred = trained_model.forward(x, the_paths) # shape == (nb sampled paths, output dim)\n",
    "    print(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trained_model.forward(X, the_path)[1])\n",
    "print(W[:n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
