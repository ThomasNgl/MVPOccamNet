{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "####\n",
    "#TODO\n",
    "\n",
    "# aussi il y a un biais au debut quil faudrait corriger en fonction de la loneur du path\n",
    "# peut etre qu il faudrait calculer le nb de possibile paths\n",
    "# reduire le sampling \n",
    "\n",
    "# faire symbolic\n",
    "# warnings\n",
    "# initialiser h0 pour rontrainer\n",
    "# check if sub and divide takes x0 and x1 in the good order\n",
    "\n",
    "import numpy as np\n",
    "from Loss import Loss\n",
    "from RON import RecurrentOccamNet\n",
    "from RONTrainer import RONTrainer\n",
    "from cocob import COCOBBackprop \n",
    "from bases import *\n",
    "\n",
    "X = [[np.array([np.cos(i), 1/100], dtype=np.float64)] for i in range(5)]\n",
    "\n",
    "Y = []\n",
    "W = []\n",
    "w = np.array([1., 1.])\n",
    "for x in X:\n",
    "    y = np.sin(np.dot(x[0],w))\n",
    "    w += x[0]*y\n",
    "    Y.append([y])\n",
    "    W.append(np.array(w.copy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "[(array([0.54030231, 0.99995   ]), array([0.85755322, 0.99995   ]), array([0.91465333, 0.99995   ]), array([0.54869613, 0.99995   ]), array([0.79387345, 0.99995   ])), (array([1.   , 0.505]), array([5.14687546, 0.53529983]), array([8.17438951, 0.56741764]), array([-0.20639517,  0.60146251]), array([33.0877184 ,  0.63755006])), (array([0.21939564, 0.21939564]), array([0.54780817, 0.35683042]), array([-0.02999662, -1.34182332]), array([-2.77744227, -5.27460726]), array([ -7.27241243, -11.10256302]))]\n",
      "[(array([0.750025, 0.750025]), array([0.99644707, 0.99644707]), array([1.33932268, 1.33932268]), array([6.04902854, 6.04902854]), array([195.22701049, 195.22701049])), (array([3.34147098, 0.52999983]), array([14.00076256,  0.56179965]), array([-20.62404245,   0.59550744]), array([95.53084739,  0.63123769]), array([-270.42303898,    0.66911174])), (array([1.0424085 , 1.38318923]), array([1.58277053, 1.93666109]), array([2.18904561, 2.53434232]), array([2.78551954, 3.38033564]), array([3.44799243, 4.35018465]))]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m optimizer \u001b[39m=\u001b[39m COCOBBackprop(r_model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trainer \u001b[39m=\u001b[39m RONTrainer(r_model, criterion, optimizer)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m trained_model \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mfit(X, Y, \u001b[39m4\u001b[39;49m, \u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/RONTrainer.py:47\u001b[0m, in \u001b[0;36mRONTrainer.fit\u001b[0;34m(self, X, Y, max_epochs, nb_sampled_paths)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mprint\u001b[39m(h_list)\n\u001b[1;32m     46\u001b[0m \u001b[39mfor\u001b[39;00m pred, target \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(pred_list, Y):\n\u001b[0;32m---> 47\u001b[0m     loss \u001b[39m=\u001b[39m\u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion\u001b[39m.\u001b[39;49mforward(pred, target, the_probas)\n\u001b[1;32m     48\u001b[0m \u001b[39m#???? If I don't use retain_graph = True I have an error\u001b[39;00m\n\u001b[1;32m     49\u001b[0m loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/Loss.py:42\u001b[0m, in \u001b[0;36mLoss.forward\u001b[0;34m(self, prediction, target, the_probas)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m# shape = (nb samples, 1)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m#prob = net.get_proba(the_keys_path, the_keys_path2)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m log_prob \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(the_probas)\n\u001b[0;32m---> 42\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39;49mlog_prob \u001b[39m*\u001b[39;49m fit\n\u001b[1;32m     43\u001b[0m mean_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     45\u001b[0m \u001b[39m# mean loss is a real value\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "r_model = RecurrentOccamNet([2], 2, [1], \n",
    "                            [[on_sin(), on_cos(), on_sum(), on_dot(), on_mul()],\n",
    "                             [on_sin(), on_cos(), on_sum(), on_dot(), on_mul()],\n",
    "                             [on_sin(), on_cos(), on_sum(), on_dot(), on_mul()], \n",
    "                            [on_identity(), on_identity()]], \n",
    "                            [0.01, 0.01, 0.01, 0.01], \n",
    "                            skip_connections=True, is_none=False)\n",
    "criterion = Loss(0.01)\n",
    "optimizer = COCOBBackprop(r_model.parameters())\n",
    "trainer = RONTrainer(r_model, criterion, optimizer)\n",
    "\n",
    "trained_model = trainer.fit(X, Y, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [0.9900, 1.0100],\n",
       "         [0.9900, 1.0100],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000]], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000],\n",
       "         [1.0100, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980,\n",
       "          0.9980, 0.9980, 0.9980],\n",
       "         [0.9980, 0.9980, 0.9980, 0.9980, 1.0100, 0.9980, 0.9980, 0.9980, 0.9980,\n",
       "          0.9980, 0.9980, 0.9980],\n",
       "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000]], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986,\n",
       "          0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 1.0100, 0.9986],\n",
       "         [1.0100, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986,\n",
       "          0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986]],\n",
       "        dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trained_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[[<bases.on_identity at 0x1683710c0>,\n",
       "    <bases.on_cos at 0x168373a30>,\n",
       "    <bases.on_cos at 0x10dcd7c40>,\n",
       "    0],\n",
       "   [<bases.on_identity at 0x168371060>, <bases.on_sin at 0x10dcd7d00>, 0]],\n",
       "  [[<bases.on_identity at 0x1683710c0>, <bases.on_sin at 0x168373880>, 1],\n",
       "   [<bases.on_identity at 0x168371060>,\n",
       "    <bases.on_dot at 0x1683733a0>,\n",
       "    1,\n",
       "    <bases.on_cos at 0x10dcd7c40>,\n",
       "    1]],\n",
       "  [[<bases.on_identity at 0x1683710c0>,\n",
       "    <bases.on_dot at 0x1683733a0>,\n",
       "    <bases.on_mul at 0x168373910>,\n",
       "    <bases.on_sin at 0x10dcd7d00>,\n",
       "    1,\n",
       "    1,\n",
       "    <bases.on_mul at 0x168373910>,\n",
       "    <bases.on_sin at 0x10dcd7d00>,\n",
       "    1,\n",
       "    <bases.on_cos at 0x10dcd7c40>,\n",
       "    1],\n",
       "   [<bases.on_identity at 0x168371060>,\n",
       "    <bases.on_sum at 0x1683739d0>,\n",
       "    <bases.on_sin at 0x10dcd7d00>,\n",
       "    0,\n",
       "    0]]],\n",
       " [[[4, [0]], [4, [1]], [2, [1]], [1, [1]], [1, [0]]],\n",
       "  [[4, [0]], [4, [1]], [3, [0]], [3, [4, 5]], [1, [1]]],\n",
       "  [[4, [0]],\n",
       "   [4, [1]],\n",
       "   [3, [4, 5]],\n",
       "   [2, [6, 7]],\n",
       "   [1, [0]],\n",
       "   [2, [6, 7]],\n",
       "   [1, [0]],\n",
       "   [1, [1]],\n",
       "   [2, [2, 3]],\n",
       "   [1, [0]]]],\n",
       " [[[8], [2], [3], [0], [0]],\n",
       "  [[12], [15], [1], [1, 3], [1]],\n",
       "  [[15], [9], [11, 11], [2, 1], [1], [2, 3], [1], [1], [2, 0], [0]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.samples_paths_and_probas(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m the_paths, the_keys_probas, the_keys_path2 \u001b[39m=\u001b[39m trained_model\u001b[39m.\u001b[39msamples_paths_and_probas(nb_sampled_paths)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(X, Y):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# This imply to compute the pred of the model for each sampled path\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     pred \u001b[39m=\u001b[39m trained_model\u001b[39m.\u001b[39;49mforward(x, the_paths) \u001b[39m# shape == (nb sampled paths, output dim)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomasnegrello/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/run.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(pred, y)\n",
      "File \u001b[0;32m~/Desktop/autoneuro/occamnet_branches/brouillon/5_grad_none/RON.py:36\u001b[0m, in \u001b[0;36mRecurrentOccamNet.forward\u001b[0;34m(self, X, the_paths, h0)\u001b[0m\n\u001b[1;32m     34\u001b[0m current_x \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(x)\n\u001b[1;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m sample_index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, nb_sampled_paths):\n\u001b[0;32m---> 36\u001b[0m     current_x[sample_index]\u001b[39m.\u001b[39;49mappend(copy\u001b[39m.\u001b[39mdeepcopy(h[sample_index]))\n\u001b[1;32m     37\u001b[0m \u001b[39m# current_x shape (nb sampled paths, input dim + hidden dim)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mforward(current_x, the_paths)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "nb_sampled_paths = 1\n",
    "\n",
    "#X = [x.append(np.array([None])) for x in X]\n",
    "X = [[copy.deepcopy(x) for _ in range(nb_sampled_paths)] for x in X]\n",
    "# Reshape Y so that shape == (nb elements, output dim).\n",
    "Y = torch.tensor(Y, requires_grad = False)\n",
    "\n",
    "the_paths, the_keys_probas, the_keys_path2 = trained_model.samples_paths_and_probas(nb_sampled_paths)\n",
    "\n",
    "for x, y in zip(X, Y):\n",
    "    # This imply to compute the pred of the model for each sampled path\n",
    "    pred = trained_model.forward(x, the_paths) # shape == (nb sampled paths, output dim)\n",
    "    print(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.5       , 1.04030231]]), array([[2.04030231, 2.04030231]]), array([[1.62415547, 2.58060461]]), array([[0.63416297, 2.16445778]]), array([[-0.01948065,  1.17446528]])]\n",
      "[[1.         1.        ]\n",
      " [1.84147098 1.84147098]\n",
      " [3.66006584 3.66006584]\n",
      " [4.08342586 4.08342586]\n",
      " [1.05621588 1.05621588]]\n"
     ]
    }
   ],
   "source": [
    "print(trained_model.forward(X, the_path)[1])\n",
    "print(W[:n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
